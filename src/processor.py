#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import re
import json
import datetime
import tempfile
import google.generativeai as genai

from .constants import (
    MAX_AUDIO_SIZE_MB,
    MAX_AUDIO_DURATION_SEC, 
    AUDIO_MIME_TYPE,
    OUTPUT_DIR,
    AI_GENERATION_CONFIG,
    SEGMENT_MERGE_CONFIG
)
from .exceptions import (
    TranscriptionError, 
    AudioProcessingError, 
    ApiConnectionError, 
    FileProcessingError
)
from .audio_processor import AudioProcessor
from .api_utils import ApiUtils
from .whisper_service import WhisperService
from .text_merger import EnhancedTextMerger
from .audio_cache import AudioCacheManager
from .utils import get_timestamp, format_duration, calculate_gemini_cost, format_token_usage
from .logger import logger

class FileProcessor:
    """éŸ³å£°/å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, output_dir, enable_cache=True, max_cache_items=5):
        self.output_dir = output_dir
        self.audio_processor = AudioProcessor()
        self.api_utils = ApiUtils()
        self.whisper_service = WhisperService()
        self.text_merger = EnhancedTextMerger(
            overlap_threshold=SEGMENT_MERGE_CONFIG['overlap_threshold'],
            min_overlap_words=SEGMENT_MERGE_CONFIG['min_overlap_words'],
            enable_context_analysis=SEGMENT_MERGE_CONFIG['enable_context_analysis']
        )

        # éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        self.enable_cache = enable_cache
        if enable_cache:
            self.cache_manager = AudioCacheManager(max_cache_items=max_cache_items)
            logger.info(f"éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½: æœ‰åŠ¹ (æœ€å¤§{max_cache_items}ä»¶)")
        else:
            self.cache_manager = None
            logger.info("éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½: ç„¡åŠ¹")
    
    def test_api_connection(self, api_key):
        """GeminiAPIã®æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        return self.api_utils.test_api_connection(api_key)

    def _check_response_safety(self, response, segment_num=None):
        """Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯

        Args:
            response: Gemini APIã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
            segment_num: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç•ªå·ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†æ™‚ã®ã¿ï¼‰

        Raises:
            TranscriptionError: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å•é¡ŒãŒã‚ã‚‹å ´åˆ
        """
        try:
            if not hasattr(response, 'candidates') or not response.candidates:
                return

            candidate = response.candidates[0]
            if not hasattr(candidate, 'finish_reason'):
                return

            finish_reason = candidate.finish_reason
            segment_info = f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_num}: " if segment_num else ""

            # finish_reasonã®ç¨®é¡:
            # 0 or FINISH_REASON_STOP: æ­£å¸¸çµ‚äº†
            # 1 or FINISH_REASON_MAX_TOKENS: ãƒˆãƒ¼ã‚¯ãƒ³æ•°ä¸Šé™
            # 2 or FINISH_REASON_SAFETY: å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚‹ãƒ–ãƒ­ãƒƒã‚¯
            # 3 or FINISH_REASON_RECITATION: å¼•ç”¨/è»¢è¼‰ã®æ¤œå‡º
            # 4: è‘—ä½œæ¨©ä¿è­·ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ¤œå‡º
            # 5 or FINISH_REASON_OTHER: ãã®ä»–ã®ç†ç”±

            if finish_reason == 2:
                error_msg = f"{segment_info}å¿œç­”ãŒå®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã£ã¦ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¾ã—ãŸ"
                solution = "éŸ³å£°ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚éæ¿€ãªè¡¨ç¾ã‚„ä¸é©åˆ‡ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€å‡¦ç†ã§ãã¾ã›ã‚“ã€‚"
                logger.error(f"{error_msg} - å¯¾å‡¦æ³•: {solution}")
                raise TranscriptionError(
                    error_msg,
                    error_code="SAFETY_FILTER",
                    user_message=f"{error_msg}\nğŸ’¡ å¯¾å‡¦æ³•: {solution}",
                    solution=solution
                )
            elif finish_reason == 3:
                error_msg = f"{segment_info}å¿œç­”ãŒæ—¢å­˜ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å¼•ç”¨ã¨ã—ã¦æ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚"
                logger.warning(error_msg)
                # å¼•ç”¨æ¤œå‡ºã¯è­¦å‘Šã®ã¿ã§ç¶šè¡Œ
            elif finish_reason == 4:
                error_msg = f"{segment_info}å¿œç­”ãŒè‘—ä½œæ¨©ä¿è­·ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã—ã¦æ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
                solution = "éŸ³å£°ã«å«ã¾ã‚Œã‚‹éŸ³æ¥½ã‚„BGMã‚’å‰Šé™¤ã™ã‚‹ã‹ã€åˆ¥ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
                logger.error(f"{error_msg} - å¯¾å‡¦æ³•: {solution}")
                raise TranscriptionError(
                    error_msg,
                    error_code="COPYRIGHT_CONTENT",
                    user_message=f"{error_msg}\nğŸ’¡ å¯¾å‡¦æ³•: {solution}",
                    solution=solution
                )
            elif finish_reason not in [0, 1]:
                error_msg = f"{segment_info}ç•°å¸¸ãªçµ‚äº†ç†ç”±ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ (finish_reason={finish_reason})"
                logger.warning(error_msg)

        except TranscriptionError:
            # TranscriptionErrorã¯ãã®ã¾ã¾å†é€å‡º
            raise
        except Exception as e:
            # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯ãƒ­ã‚°ã®ã¿
            logger.debug(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def get_output_files(self):
        """å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        files = []
        for file in os.listdir(self.output_dir):
            if file.endswith('.txt'):
                file_path = os.path.join(self.output_dir, file)
                mod_time = os.path.getmtime(file_path)
                mod_date = datetime.datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d %H:%M')
                size = os.path.getsize(file_path)
                size_str = f"{size / 1024:.1f} KB"
                files.append((file, mod_date, size_str, mod_time))
        
        # æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        files.sort(key=lambda x: x[3], reverse=True)
        return files
    
    def process_file(self, input_file, process_type, api_key, prompts, status_callback=None, 
                    preferred_model=None, engine='gemini', whisper_model='base'):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã€çµæœã‚’è¿”ã™"""
        start_time = datetime.datetime.now()
        
        def update_status(message):
            logger.info(message)
            if status_callback:
                status_callback(message)
        
        try:
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰
            audio_path, cached_segments, from_cache = self._prepare_audio_file(input_file, update_status)

            # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œï¼ˆã‚¨ãƒ³ã‚¸ãƒ³ã«å¿œã˜ã¦åˆ†å²ï¼‰
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ãŸå ´åˆã¯ã€ãã‚Œã‚’ä½¿ç”¨
            if engine == 'whisper':
                transcription = self._perform_whisper_transcription(
                    audio_path, update_status, whisper_model, cached_segments
                )
            else:
                transcription = self._perform_transcription(
                    audio_path, api_key, update_status, preferred_model, cached_segments
                )
            
            # è¿½åŠ å‡¦ç†ï¼ˆå¿…è¦ãªå ´åˆï¼‰
            final_text = self._perform_additional_processing(
                transcription, process_type, prompts, api_key, update_status, preferred_model
            )
            
            # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            output_path = self._save_result(
                input_file, final_text, process_type, prompts, start_time, update_status
            )
            
            return output_path
            
        except Exception as e:
            logger.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
            update_status(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise FileProcessingError(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    def _prepare_audio_file(self, input_file, update_status):
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ï¼ˆå¤‰æ›ãƒ»åœ§ç¸®ãƒ»åˆ†å‰²ï¼‰

        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚Œã°å†åˆ©ç”¨ã€ãªã‘ã‚Œã°å‡¦ç†ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜

        Returns:
            (audio_path, segment_files, from_cache) ã®ã‚¿ãƒ—ãƒ«
        """
        # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—
        original_size_mb = os.path.getsize(input_file) / (1024 * 1024)
        audio_duration_sec = self.audio_processor.get_audio_duration(input_file)
        duration_str = format_duration(audio_duration_sec) if audio_duration_sec else "ä¸æ˜"

        logger.info(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™é–‹å§‹: {os.path.basename(input_file)}, ã‚µã‚¤ã‚º={original_size_mb:.2f}MB, é•·ã•={duration_str}")
        update_status(f"å‡¦ç†é–‹å§‹: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º={original_size_mb:.2f}MB, é•·ã•={duration_str}")

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
        if self.enable_cache and self.cache_manager:
            cache_entry = self.cache_manager.get_cache_entry(input_file)
            if cache_entry:
                cache_id = cache_entry['cache_id']
                processed_audio, segments = self.cache_manager.get_cached_files(cache_id)

                if processed_audio:
                    update_status(f"âœ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿: {os.path.basename(input_file)}")
                    logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨: processed={processed_audio}, segments={len(segments) if segments else 0}")
                    return processed_audio, segments, True

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„å ´åˆã¯é€šå¸¸å‡¦ç†
        update_status("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›ä¸­...")
        audio_path = self.audio_processor.convert_audio(input_file)

        # é•·æ™‚é–“éŸ³å£°ã‚„å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã¯åˆ†å‰²ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
        file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
        needs_split = (
            file_size_mb > MAX_AUDIO_SIZE_MB or
            (audio_duration_sec and audio_duration_sec > MAX_AUDIO_DURATION_SEC)
        )

        segment_files = None

        if needs_split:
            if file_size_mb > MAX_AUDIO_SIZE_MB:
                update_status(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚åœ§ç¸®ã‚’å®Ÿè¡Œã—ã¾ã™")
                audio_path = self.audio_processor.compress_audio(
                    audio_path, MAX_AUDIO_SIZE_MB, update_status
                )
                if not audio_path:
                    raise AudioProcessingError("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åœ§ç¸®ã«å¤±æ•—ã—ã¾ã—ãŸ")

            # åˆ†å‰²å‡¦ç†
            update_status("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ä¸­...")
            segment_files = self.audio_processor.split_audio(audio_path, callback=update_status)
            if segment_files:
                update_status(f"{len(segment_files)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã—ã¾ã—ãŸ")

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        if self.enable_cache and self.cache_manager:
            try:
                self.cache_manager.save_cache_entry(
                    input_file, audio_path, segment_files, audio_duration_sec
                )
                update_status("âœ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ãŸ")
            except Exception as e:
                logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")

        return audio_path, segment_files, False
    
    def _perform_transcription(self, audio_path, api_key, update_status, preferred_model=None, cached_segments=None):
        """æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’ä½¿ç”¨
        if cached_segments:
            logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨: {len(cached_segments)}å€‹")
            return self._perform_segmented_transcription(
                audio_path, api_key, update_status, preferred_model, cached_segments
            )

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨é•·ã•ã‚’å†ãƒã‚§ãƒƒã‚¯
        file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
        audio_duration_sec = self.audio_processor.get_audio_duration(audio_path)

        needs_split = (
            file_size_mb > MAX_AUDIO_SIZE_MB or
            (audio_duration_sec and audio_duration_sec > MAX_AUDIO_DURATION_SEC)
        )

        if needs_split:
            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²å‡¦ç†ã‚’å®Ÿè¡Œ: ã‚µã‚¤ã‚º={file_size_mb:.2f}MB, é•·ã•={audio_duration_sec}s")
            return self._perform_segmented_transcription(audio_path, api_key, update_status, preferred_model)
        else:
            logger.info(f"å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’å®Ÿè¡Œ: ã‚µã‚¤ã‚º={file_size_mb:.2f}MB")
            return self._perform_single_transcription(audio_path, api_key, update_status, preferred_model)
    
    def _perform_whisper_transcription(self, audio_path, update_status, whisper_model='base', cached_segments=None):
        """Whisperã‚’ä½¿ç”¨ã—ãŸæ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’ä½¿ç”¨
        if cached_segments:
            logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨: {len(cached_segments)}å€‹")
            return self._perform_whisper_segmented_transcription(
                audio_path, update_status, whisper_model, cached_segments
            )

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯
        file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
        audio_duration_sec = self.audio_processor.get_audio_duration(audio_path)

        # Whisperã¯å¤§ãã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‡¦ç†ã§ãã‚‹ãŒã€é•·æ™‚é–“ã®éŸ³å£°ã¯åˆ†å‰²ã—ãŸæ–¹ãŒå®‰å®š
        needs_split = audio_duration_sec and audio_duration_sec > MAX_AUDIO_DURATION_SEC

        if needs_split:
            logger.info(f"Whisperåˆ†å‰²å‡¦ç†ã‚’å®Ÿè¡Œ: é•·ã•={audio_duration_sec}s")
            return self._perform_whisper_segmented_transcription(audio_path, update_status, whisper_model)
        else:
            logger.info(f"Whisperå˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’å®Ÿè¡Œ: ã‚µã‚¤ã‚º={file_size_mb:.2f}MB")
            return self._perform_whisper_single_transcription(audio_path, update_status, whisper_model)
    
    def _perform_single_transcription(self, audio_path, api_key, update_status, preferred_model=None):
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—"""
        genai.configure(api_key=api_key)
        model_name = self.api_utils.get_best_available_model(api_key, preferred_model)

        # éŸ³å£°ã®é•·ã•ã‚’å–å¾—ï¼ˆæ–™é‡‘è¨ˆç®—ç”¨ï¼‰
        audio_duration_sec = self.audio_processor.get_audio_duration(audio_path)

        # ãƒ¢ãƒ‡ãƒ«åã‚’ç›®ç«‹ã¤ã‚ˆã†ã«è¡¨ç¤º
        logger.info(f"âœ“ é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: {model_name}")
        update_status(f"âœ“ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
        update_status(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ä¸­...")

        model = genai.GenerativeModel(
            model_name,
            generation_config=AI_GENERATION_CONFIG
        )

        with open(audio_path, 'rb') as audio_file:
            audio_data = audio_file.read()

        prompt = """ã“ã®éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ã‚’æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚ä»¥ä¸‹ã®ç‚¹ã‚’å®ˆã£ã¦æ­£ç¢ºã«æ›¸ãèµ·ã“ã—ã¦ãã ã•ã„ï¼š

1. è©±ã•ã‚ŒãŸå†…å®¹ã‚’ãã®ã¾ã¾æ–‡å­—ã«èµ·ã“ã™
2. è©±è€…ãŒè¤‡æ•°ã„ã‚‹å ´åˆã¯ã€è©±è€…ã®åŒºåˆ¥ã‚’è¡¨è¨˜ã™ã‚‹
3. è‡ªç„¶ãªæ–‡ç« ã®æµã‚Œã‚’ä¿ã¤
4. ä¸æ˜ç­ãªéƒ¨åˆ†ã¯[ä¸æ˜ç­]ã¨è¨˜è¼‰ã™ã‚‹
5. é•·ã„æ²ˆé»™ã¯[é–“]ã¨è¨˜è¼‰ã™ã‚‹

æ­£ç¢ºæ€§ã¨ä¸€è²«æ€§ã‚’æœ€å„ªå…ˆã«ã—ã¦ãã ã•ã„ã€‚"""

        parts = [
            {"inline_data": {"mime_type": AUDIO_MIME_TYPE, "data": audio_data}},
            {"text": prompt}
        ]

        response = model.generate_content(parts)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
        self._check_response_safety(response)

        if not response.text or response.text.strip() == "":
            raise TranscriptionError("æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã§ã—ãŸ")

        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã¨æ–™é‡‘ã‚’è¨ˆç®—ãƒ»è¡¨ç¤º
        if hasattr(response, 'usage_metadata') and response.usage_metadata:
            usage = response.usage_metadata
            input_tokens = getattr(usage, 'prompt_token_count', 0)
            output_tokens = getattr(usage, 'candidates_token_count', 0)

            # éŸ³å£°å…¥åŠ›ã®ãŸã‚ is_audio_input=Trueã€Gemini 1.5ã®å ´åˆã¯ç§’æ•°ã‚‚æ¸¡ã™
            cost_info = calculate_gemini_cost(
                model_name, input_tokens, output_tokens,
                is_audio_input=True, audio_duration_seconds=audio_duration_sec
            )
            usage_text = format_token_usage(cost_info)
            update_status(f"ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡: {usage_text}")

        return response.text
    
    def _perform_segmented_transcription(self, audio_path, api_key, update_status, preferred_model=None, cached_segments=None):
        """åˆ†å‰²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ï¼ˆã‚¹ãƒãƒ¼ãƒˆçµ±åˆä»˜ãï¼‰"""
        genai.configure(api_key=api_key)
        model_name = self.api_utils.get_best_available_model(api_key, preferred_model)

        # ãƒ¢ãƒ‡ãƒ«åã‚’ç›®ç«‹ã¤ã‚ˆã†ã«è¡¨ç¤º
        logger.info(f"âœ“ é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: {model_name}")
        update_status(f"âœ“ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨
        if cached_segments:
            update_status(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨")
            segment_files = cached_segments
            update_status(f"{len(segment_files)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§å‡¦ç†ã—ã¾ã™")
        else:
            update_status(f"éŸ³å£°ã®é•·ã•ãŒé•·ã„ãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™")

            # éŸ³å£°ã‚’åˆ†å‰²
            segment_files = self.audio_processor.split_audio(audio_path, callback=update_status)
            if not segment_files:
                raise AudioProcessingError("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²ã«å¤±æ•—ã—ã¾ã—ãŸ")

            update_status(f"{len(segment_files)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã—ã¾ã—ãŸ")
        
        segment_transcriptions = []
        segment_info = []
        segment_costs = []
        segment_errors = []  # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¨˜éŒ²
        
        try:
            for i, segment_file in enumerate(segment_files):
                update_status(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {i+1}/{len(segment_files)} ã‚’å‡¦ç†ä¸­")
                
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ–‡å­—èµ·ã“ã—ï¼ˆæ”¹å–„ç‰ˆï¼‰
                result = self._transcribe_segment_enhanced(
                    segment_file, api_key, i+1, len(segment_files), model_name
                )
                
                if isinstance(result, tuple):
                    segment_transcription, cost_info = result
                    if cost_info:
                        segment_costs.append(cost_info)
                else:
                    segment_transcription = result
                
                segment_transcriptions.append(segment_transcription)
                
                # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ã¨è¨˜éŒ²
                if "å‡¦ç†ã‚¨ãƒ©ãƒ¼" in segment_transcription:
                    segment_errors.append({
                        'segment_index': i+1,
                        'error_text': segment_transcription
                    })
                
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’è¨˜éŒ²ï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰
                segment_info.append({
                    'segment_index': i,
                    'total_segments': len(segment_files),
                    'file_path': segment_file
                })
        
        finally:
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self._cleanup_segments(segment_files, audio_path)
            
            # ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã‚’è¨˜éŒ²
            if segment_errors:
                error_summary = {
                    'summary': {
                        'total_segments': len(segment_files),
                        'failed_segments': len(segment_errors),
                        'success_segments': len(segment_files) - len(segment_errors),
                        'success_rate': f"{((len(segment_files) - len(segment_errors)) / len(segment_files) * 100):.1f}%"
                    },
                    'errors': segment_errors,
                    'recommendations': [
                        "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯æ–‡å­—èµ·ã“ã—çµæœã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
                        "ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã¯å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
                        "ã‚¨ãƒ©ãƒ¼ãŒç¶šãå ´åˆã¯ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚„å“è³ªã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                    ]
                }
                logger.warning(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼: {json.dumps(error_summary, ensure_ascii=False)}")

                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
                update_status(
                    f"\nâš ï¸ ä¸€éƒ¨ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n"
                    f"- æˆåŠŸ: {error_summary['summary']['success_segments']}/{error_summary['summary']['total_segments']}\n"
                    f"- å¤±æ•—: {error_summary['summary']['failed_segments']}/{error_summary['summary']['total_segments']}\n"
                    f"è©³ç´°ã¯ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                )

                # ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                try:
                    audio_dir = os.path.dirname(audio_path) if audio_path else OUTPUT_DIR
                    if audio_dir and os.path.exists(audio_dir):
                        error_summary_path = os.path.join(
                            audio_dir,
                            f"transcription_errors_{get_timestamp()}.json"
                        )
                        with open(error_summary_path, 'w', encoding='utf-8') as f:
                            json.dump(error_summary, f, ensure_ascii=False, indent=2)
                        logger.info(f"ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜: {error_summary_path}")
                    else:
                        logger.warning(f"ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã®ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {audio_dir}")
                except Exception as e:
                    logger.error(f"ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã®ä¿å­˜ã«å¤±æ•—: {str(e)}")
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã®ã‚³ã‚¹ãƒˆæƒ…å ±ã‚’é›†è¨ˆ
        if segment_costs:
            total_input_tokens = sum(cost["input_tokens"] for cost in segment_costs)
            total_output_tokens = sum(cost["output_tokens"] for cost in segment_costs)
            total_cost = sum(cost["total_cost"] for cost in segment_costs)
            
            combined_cost_info = {
                "input_tokens": total_input_tokens,
                "output_tokens": total_output_tokens,
                "total_cost": total_cost,
                "input_cost": sum(cost["input_cost"] for cost in segment_costs),
                "output_cost": sum(cost["output_cost"] for cost in segment_costs)
            }
            
            usage_text = format_token_usage(combined_cost_info)
            update_status(f"å…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡: {usage_text}")
        
        # ã‚¹ãƒãƒ¼ãƒˆçµ±åˆã‚’å®Ÿè¡Œ
        if SEGMENT_MERGE_CONFIG['enable_smart_merge']:
            update_status("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’çµ±åˆä¸­...")
            merged_text = self.text_merger.merge_segments_with_context(
                segment_transcriptions, segment_info
            )
            update_status("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµ±åˆå®Œäº†")
            return merged_text
        else:
            # å¾“æ¥ã®æ–¹æ³•ã§çµåˆ
            return "\n\n".join(segment_transcriptions)
    
    def _transcribe_segment_enhanced(self, segment_file, api_key, segment_num, total_segments, model_name):
        """æ”¹å–„ã•ã‚ŒãŸå˜ä¸€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ–‡å­—èµ·ã“ã—"""
        try:
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®éŸ³å£°ã®é•·ã•ã‚’å–å¾—ï¼ˆæ–™é‡‘è¨ˆç®—ç”¨ï¼‰
            segment_duration_sec = self.audio_processor.get_audio_duration(segment_file)

            model = genai.GenerativeModel(
                model_name,
                generation_config=AI_GENERATION_CONFIG
            )

            with open(segment_file, 'rb') as audio_file:
                audio_data = audio_file.read()

            # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚’è€ƒæ…®ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            if segment_num == 1:
                context_instruction = "ã“ã‚Œã¯éŸ³å£°ã®æœ€åˆã®éƒ¨åˆ†ã§ã™ã€‚"
            elif segment_num == total_segments:
                context_instruction = "ã“ã‚Œã¯éŸ³å£°ã®æœ€å¾Œã®éƒ¨åˆ†ã§ã™ã€‚å‰ã®éƒ¨åˆ†ã‹ã‚‰è‡ªç„¶ã«ç¶šãã‚ˆã†ã«æ–‡å­—èµ·ã“ã—ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"
            else:
                context_instruction = f"ã“ã‚Œã¯éŸ³å£°ã®ä¸­é–“éƒ¨åˆ†ï¼ˆ{segment_num}/{total_segments}ï¼‰ã§ã™ã€‚å‰å¾Œã®éƒ¨åˆ†ã¨è‡ªç„¶ã«ç¹‹ãŒã‚‹ã‚ˆã†ã«æ–‡å­—èµ·ã“ã—ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"

            prompt = f"""ã“ã®éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ã‚’æ—¥æœ¬èªã§è¡Œã£ã¦ãã ã•ã„ã€‚

{context_instruction}

ä»¥ä¸‹ã®ç‚¹ã‚’å®ˆã£ã¦æ­£ç¢ºã«æ›¸ãèµ·ã“ã—ã¦ãã ã•ã„ï¼š
1. è©±ã•ã‚ŒãŸå†…å®¹ã‚’ãã®ã¾ã¾æ–‡å­—ã«èµ·ã“ã™
2. è©±è€…ãŒè¤‡æ•°ã„ã‚‹å ´åˆã¯ã€è©±è€…ã®åŒºåˆ¥ã‚’è¡¨è¨˜ã™ã‚‹
3. è‡ªç„¶ãªæ–‡ç« ã®æµã‚Œã‚’ä¿ã¤
4. ä¸æ˜ç­ãªéƒ¨åˆ†ã¯[ä¸æ˜ç­]ã¨è¨˜è¼‰ã™ã‚‹
5. æ–‡ã®é€”ä¸­ã§åˆ‡ã‚Œã‚‹å ´åˆã¯ã€è‡ªç„¶ãªåŒºåˆ‡ã‚Šã§çµ‚ã‚ã‚‰ã›ã‚‹
6. é‡è¤‡ã‚„ç¹°ã‚Šè¿”ã—ãŒã‚ã‚‹å ´åˆã¯é©åˆ‡ã«å‡¦ç†ã™ã‚‹

æ­£ç¢ºæ€§ã¨ä¸€è²«æ€§ã‚’æœ€å„ªå…ˆã«ã—ã€å¾Œã§ä»–ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨çµ±åˆã•ã‚Œã‚‹ã“ã¨ã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚"""

            parts = [
                {"inline_data": {"mime_type": AUDIO_MIME_TYPE, "data": audio_data}},
                {"text": prompt}
            ]

            response = model.generate_content(parts)

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
            self._check_response_safety(response, segment_num=segment_num)

            if not response.text or response.text.strip() == "":
                raise TranscriptionError(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_num} ã®æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã§ã—ãŸ")

            # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†ã§ã¯è¡¨ç¤ºã¯æ§ãˆã‚ã«ï¼‰
            segment_cost_info = None
            if hasattr(response, 'usage_metadata') and response.usage_metadata:
                usage = response.usage_metadata
                input_tokens = getattr(usage, 'prompt_token_count', 0)
                output_tokens = getattr(usage, 'candidates_token_count', 0)
                # Gemini 1.5ã®å ´åˆã¯ç§’æ•°ã‚‚æ¸¡ã™
                segment_cost_info = calculate_gemini_cost(
                    model_name, input_tokens, output_tokens,
                    is_audio_input=True, audio_duration_seconds=segment_duration_sec
                )

            return response.text.strip(), segment_cost_info
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±ã‚’è¨˜éŒ²
            error_details = {
                'segment_num': segment_num,
                'total_segments': total_segments,
                'segment_file': segment_file,
                'error_type': type(e).__name__,
                'error_message': str(e),
                'model': model_name
            }
            
            # ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡ã«ã‚ˆã£ã¦è©³ç´°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨å¯¾å‡¦æ³•ã‚’ä½œæˆ
            error_str = str(e).lower()

            if 'audio input modality is not enabled' in error_str or 'audio input is not supported' in error_str:
                error_category = "ãƒ¢ãƒ‡ãƒ«éå¯¾å¿œ"
                error_detail = "é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯éŸ³å£°å…¥åŠ›ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“"
                solution = "åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚Flashç³»ãƒ¢ãƒ‡ãƒ«ï¼ˆgemini-2.5-flashç­‰ï¼‰ã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
            elif 'rate limit' in error_str or '429' in error_str:
                error_category = "APIãƒ¬ãƒ¼ãƒˆåˆ¶é™"
                error_detail = "APIã®å‘¼ã³å‡ºã—å›æ•°ãŒä¸Šé™ã«é”ã—ã¾ã—ãŸ"
                solution = "æ•°åˆ†å¾…ã£ã¦ã‹ã‚‰å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚ã¾ãŸã¯ã€æœ‰æ–™ãƒ—ãƒ©ãƒ³ã¸ã®ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚’ã”æ¤œè¨ãã ã•ã„ã€‚"
            elif 'timeout' in error_str:
                error_category = "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ"
                error_detail = "APIå¿œç­”ã«æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã¾ã—ãŸ"
                solution = "éŸ³å£°ã®å†…å®¹ãŒè¤‡é›‘ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
            elif 'network' in error_str or 'connection' in error_str:
                error_category = "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶š"
                error_detail = "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã«å•é¡ŒãŒã‚ã‚Šã¾ã™"
                solution = "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ã‹ã‚‰å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
            elif 'authentication' in error_str or '401' in str(e) or '403' in str(e):
                error_category = "èªè¨¼å¤±æ•—"
                error_detail = "APIã‚­ãƒ¼ãŒç„¡åŠ¹ã¾ãŸã¯æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“"
                solution = "APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            elif 'finish_reason' in error_str and '4' in error_str:
                error_category = "è‘—ä½œæ¨©ä¿è­·ã‚³ãƒ³ãƒ†ãƒ³ãƒ„"
                error_detail = "éŸ³æ¥½ã‚„è‘—ä½œæ¨©ä¿è­·ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
                solution = "éŸ³å£°ã«å«ã¾ã‚Œã‚‹éŸ³æ¥½ã‚„BGMã‚’å‰Šé™¤ã™ã‚‹ã‹ã€åˆ¥ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
            elif 'copyrighted' in error_str or 'è‘—ä½œæ¨©' in str(e):
                error_category = "è‘—ä½œæ¨©ä¿è­·ã‚³ãƒ³ãƒ†ãƒ³ãƒ„"
                error_detail = "éŸ³æ¥½ã‚„è‘—ä½œæ¨©ä¿è­·ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
                solution = "éŸ³å£°ã«å«ã¾ã‚Œã‚‹éŸ³æ¥½ã‚„BGMã‚’å‰Šé™¤ã™ã‚‹ã‹ã€åˆ¥ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
            elif 'safety' in error_str or 'å®‰å…¨æ€§' in str(e) or 'blocked' in error_str:
                error_category = "å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"
                error_detail = "éŸ³å£°ã®å†…å®¹ãŒå®‰å…¨æ€§åŸºæº–ã«æŠµè§¦ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
                solution = "éŸ³å£°ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚éæ¿€ãªè¡¨ç¾ã‚„ä¸é©åˆ‡ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€å‡¦ç†ã§ãã¾ã›ã‚“ã€‚"
            elif '500' in str(e) or 'internal' in error_str:
                error_category = "ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼"
                error_detail = f"{type(e).__name__}"
                solution = "Googleå´ã®ã‚µãƒ¼ãƒãƒ¼ã§ä¸€æ™‚çš„ãªå•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚æ•°åˆ†å¾…ã£ã¦ã‹ã‚‰å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
            else:
                error_category = "äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼"
                error_detail = f"{type(e).__name__}: {str(e)}"
                solution = "ã‚¨ãƒ©ãƒ¼ãŒç¶šãå ´åˆã¯ã€åˆ¥ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è©¦ã™ã‹ã€ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

            # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            try:
                segment_dir = os.path.dirname(segment_file) if segment_file else tempfile.gettempdir()
                if segment_dir and os.path.exists(segment_dir):
                    error_log_path = os.path.join(
                        segment_dir,
                        f"segment_{segment_num}_error.log"
                    )
                    error_details['error_category'] = error_category
                    error_details['error_detail'] = error_detail
                    error_details['solution'] = solution
                    with open(error_log_path, 'w', encoding='utf-8') as f:
                        json.dump(error_details, f, ensure_ascii=False, indent=2)
            except Exception as log_error:
                logger.debug(f"ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ä¿å­˜ã«å¤±æ•—: {str(log_error)}")

            # ã‚ã‹ã‚Šã‚„ã™ã„ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
            user_friendly_error = (
                f"\nâš ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_num} å‡¦ç†ã‚¨ãƒ©ãƒ¼\n"
                f"ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥: {error_category}\n"
                f"è©³ç´°: {error_detail}\n"
                f"ğŸ’¡ å¯¾å‡¦æ³•: {solution}"
            )

            logger.error(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_num} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {error_category} - {error_detail}")
            logger.debug(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {json.dumps(error_details, ensure_ascii=False)}")

            return f"[ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_num} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {error_category} - {error_detail}]", None
    
    def _perform_whisper_single_transcription(self, audio_path, update_status, whisper_model='base'):
        """Whisperã‚’ä½¿ç”¨ã—ãŸå˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—"""
        update_status(f"Whisperã§æ–‡å­—èµ·ã“ã—ä¸­... (ãƒ¢ãƒ‡ãƒ«: {whisper_model})")
        
        try:
            # Whisperã§æ–‡å­—èµ·ã“ã—
            text, metadata = self.whisper_service.transcribe(
                audio_path, 
                model_name=whisper_model,
                language='ja'
            )
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’è¡¨ç¤º
            duration = metadata.get('duration', 0)
            segments = metadata.get('segments', 0)
            device = metadata.get('device', 'CPU')
            
            update_status(
                f"Whisperæ–‡å­—èµ·ã“ã—å®Œäº†: "
                f"é•·ã•={format_duration(duration)}, "
                f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°={segments}, "
                f"ãƒ‡ãƒã‚¤ã‚¹={device}"
            )
            
            return text
            
        except Exception as e:
            logger.error(f"Whisperæ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise TranscriptionError(f"Whisperæ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    def _perform_whisper_segmented_transcription(self, audio_path, update_status, whisper_model='base', cached_segments=None):
        """Whisperã‚’ä½¿ç”¨ã—ãŸåˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨
        if cached_segments:
            update_status(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’Whisperã§å‡¦ç†ã—ã¾ã™ (ãƒ¢ãƒ‡ãƒ«: {whisper_model})")
            segment_files = cached_segments
            update_status(f"{len(segment_files)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§å‡¦ç†ã—ã¾ã™")
        else:
            update_status(f"éŸ³å£°ãŒé•·ã„ãŸã‚ã€åˆ†å‰²ã—ã¦Whisperã§å‡¦ç†ã—ã¾ã™ (ãƒ¢ãƒ‡ãƒ«: {whisper_model})")

            # éŸ³å£°ã‚’åˆ†å‰²
            segment_files = self.audio_processor.split_audio(audio_path, callback=update_status)
            if not segment_files:
                raise AudioProcessingError("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²ã«å¤±æ•—ã—ã¾ã—ãŸ")

            update_status(f"{len(segment_files)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã—ã¾ã—ãŸ")
        
        segment_transcriptions = []
        segment_info = []
        
        try:
            for i, segment_file in enumerate(segment_files):
                update_status(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {i+1}/{len(segment_files)} ã‚’Whisperã§å‡¦ç†ä¸­")
                
                # Whisperã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ–‡å­—èµ·ã“ã—
                text, metadata = self.whisper_service.transcribe_segment(
                    segment_file, 
                    segment_num=i+1,
                    total_segments=len(segment_files),
                    model_name=whisper_model,
                    language='ja'
                )
                
                segment_transcriptions.append(text)
                
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’è¨˜éŒ²
                segment_info.append({
                    'segment_index': i,
                    'total_segments': len(segment_files),
                    'file_path': segment_file,
                    'metadata': metadata
                })
        
        finally:
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self._cleanup_segments(segment_files, audio_path)
        
        # ã‚¹ãƒãƒ¼ãƒˆçµ±åˆã‚’å®Ÿè¡Œ
        if SEGMENT_MERGE_CONFIG['enable_smart_merge']:
            update_status("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’çµ±åˆä¸­...")
            merged_text = self.text_merger.merge_segments_with_context(
                segment_transcriptions, segment_info
            )
            update_status("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµ±åˆå®Œäº†")
            return merged_text
        else:
            # å¾“æ¥ã®æ–¹æ³•ã§çµåˆ
            return "\n\n".join(segment_transcriptions)
    
    def _cleanup_segments(self, segment_files, original_audio_path):
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        for segment_file in segment_files:
            if segment_file != original_audio_path and os.path.exists(segment_file):
                try:
                    os.unlink(segment_file)
                except:
                    pass
    
    def _perform_additional_processing(self, transcription, process_type, prompts, api_key, update_status, preferred_model=None):
        """è¿½åŠ å‡¦ç†ï¼ˆè¦ç´„ã€è­°äº‹éŒ²ä½œæˆãªã©ï¼‰"""
        if process_type == "transcription":
            return transcription

        if process_type not in prompts:
            raise FileProcessingError(f"æŒ‡å®šã•ã‚ŒãŸå‡¦ç†ã‚¿ã‚¤ãƒ— '{process_type}' ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®šã«å­˜åœ¨ã—ã¾ã›ã‚“")

        # è¿½åŠ å‡¦ç†ã¯GeminiãŒå¿…è¦
        if not api_key:
            raise ApiConnectionError("è¿½åŠ å‡¦ç†ï¼ˆè¦ç´„ãƒ»è­°äº‹éŒ²ä½œæˆãªã©ï¼‰ã«ã¯Gemini APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")

        process_name = prompts[process_type]["name"]
        genai.configure(api_key=api_key)
        model_name = self.api_utils.get_best_available_model(api_key, preferred_model)

        # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º
        logger.info(f"âœ“ {process_name}ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
        update_status(f"âœ“ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
        update_status(f"{process_name}ã‚’ç”Ÿæˆä¸­...")
        
        prompt = prompts[process_type]["prompt"].replace("{transcription}", transcription)
        
        model = genai.GenerativeModel(
            model_name,
            generation_config=AI_GENERATION_CONFIG
        )
        
        response = model.generate_content(prompt)
        if not response.text:
            raise TranscriptionError(f"{process_name}ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã¨æ–™é‡‘ã‚’è¨ˆç®—ãƒ»è¡¨ç¤ºï¼ˆãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ï¼‰
        if hasattr(response, 'usage_metadata') and response.usage_metadata:
            usage = response.usage_metadata
            input_tokens = getattr(usage, 'prompt_token_count', 0)
            output_tokens = getattr(usage, 'candidates_token_count', 0)
            
            # ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã®ãŸã‚ is_audio_input=False
            cost_info = calculate_gemini_cost(model_name, input_tokens, output_tokens, is_audio_input=False)
            usage_text = format_token_usage(cost_info)
            update_status(f"{process_name}ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡: {usage_text}")
        
        return response.text
    
    def _save_result(self, input_file, final_text, process_type, prompts, start_time, update_status):
        """çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        timestamp = get_timestamp()
        base_name = os.path.splitext(os.path.basename(input_file))[0]
        
        # process_typeãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåã‚’ä½¿ç”¨
        if process_type in prompts:
            process_name = prompts[process_type]["name"]
        else:
            process_name = "æ–‡å­—èµ·ã“ã—"
        
        output_filename = f"{base_name}_{process_name}_{timestamp}.txt"
        output_path = os.path.join(self.output_dir, output_filename)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(final_text)
        
        # å‡¦ç†å®Œäº†ã®ãƒ­ã‚°
        end_time = datetime.datetime.now()
        process_time = end_time - start_time
        process_seconds = process_time.total_seconds()
        process_time_str = f"{int(process_seconds // 60)}åˆ†{int(process_seconds % 60)}ç§’"
        
        output_size_kb = os.path.getsize(output_path) / 1024
        update_status(
            f"å‡¦ç†å®Œäº†: {output_filename}\n"
            f"- å‡¦ç†æ™‚é–“: {process_time_str}\n"
            f"- å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {output_size_kb:.2f}KB"
        )
        
        return output_path
    
    def process_transcription_file(self, transcription_file, prompt_key, api_key, prompts, status_callback=None):
        """æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã®è¿½åŠ å‡¦ç†ã‚’å®Ÿè¡Œ"""
        start_time = datetime.datetime.now()
        
        def update_status(message):
            logger.info(message)
            if status_callback:
                status_callback(message)
        
        try:
            # æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            file_size_kb = os.path.getsize(transcription_file) / 1024
            update_status(f"æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ{file_size_kb:.1f}KBï¼‰ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            
            with open(transcription_file, 'r', encoding='utf-8') as f:
                transcription = f.read()
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæƒ…å ±å–å¾—
            if prompt_key not in prompts:
                raise FileProcessingError(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ¼ '{prompt_key}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            prompt_info = prompts[prompt_key]
            process_name = prompt_info["name"]
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ™ãƒ¼ã‚¹éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆå…ƒã®æ–‡å­—èµ·ã“ã—å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
            base_name = os.path.basename(transcription_file)
            match = re.match(r'(.+?)_æ–‡å­—èµ·ã“ã—_\d+_\d+\.txt', base_name)
            if match:
                base_name = match.group(1)
            else:
                match = re.match(r'(.+?)_\d+_\d+\.txt', base_name)
                if match:
                    base_name = match.group(1)
            
            # APIã‚’ä½¿ç”¨ã—ã¦å‡¦ç†
            genai.configure(api_key=api_key)
            model_name = self.api_utils.get_best_available_model(api_key)

            # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º
            logger.info(f"âœ“ {process_name}ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
            update_status(f"âœ“ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
            update_status(f"{process_name}ã‚’ç”Ÿæˆä¸­...")
            
            model = genai.GenerativeModel(
                model_name,
                generation_config=AI_GENERATION_CONFIG
            )
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ–‡å­—èµ·ã“ã—çµæœã‚’åŸ‹ã‚è¾¼ã‚€
            prompt = prompt_info["prompt"].replace("{transcription}", transcription)
            
            response = model.generate_content(prompt)
            if not response.text:
                raise TranscriptionError(f"{process_name}ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
            timestamp = get_timestamp()
            output_filename = f"{base_name}_{process_name}_{timestamp}.txt"
            output_path = os.path.join(self.output_dir, output_filename)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            # å‡¦ç†å®Œäº†ã®ãƒ­ã‚°
            end_time = datetime.datetime.now()
            process_time = end_time - start_time
            process_seconds = process_time.total_seconds()
            process_time_str = f"{int(process_seconds // 60)}åˆ†{int(process_seconds % 60)}ç§’"
            
            output_size_kb = os.path.getsize(output_path) / 1024
            update_status(
                f"å‡¦ç†å®Œäº†: {os.path.basename(output_path)}\n"
                f"- å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_kb:.1f}KB\n"
                f"- å‡¦ç†æ™‚é–“: {process_time_str}\n"
                f"- ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}"
            )
            
            return output_path
            
        except Exception as e:
            update_status(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise FileProcessingError(f"æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
