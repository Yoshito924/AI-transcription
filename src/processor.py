#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import re
import json
import shutil
import datetime
import tempfile
import google.generativeai as genai

from .constants import (
    MAX_AUDIO_SIZE_MB,
    MAX_AUDIO_DURATION_SEC,
    AUDIO_MIME_TYPE,
    OUTPUT_DIR,
    AI_GENERATION_CONFIG,
    SEGMENT_MERGE_CONFIG,
    SAFETY_SETTINGS_TRANSCRIPTION,
    SUMMARY_TITLE_MAX_LENGTH,
    TITLE_GENERATION_MODELS
)
from .exceptions import (
    TranscriptionError, 
    AudioProcessingError, 
    ApiConnectionError, 
    FileProcessingError
)
from .audio_processor import AudioProcessor
from .api_utils import ApiUtils
from .whisper_service import WhisperService
from .whisper_api_service import WhisperApiService
from .text_merger import EnhancedTextMerger
from .audio_cache import AudioCacheManager
from .utils import (
    get_timestamp, format_duration, calculate_gemini_cost, format_token_usage,
    get_file_size_mb, get_file_size_kb, format_process_time,
    extract_usage_metadata, process_usage_metadata,
    sanitize_filename
)
from .logger import logger

class FileProcessor:
    """éŸ³å£°/å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, output_dir, enable_cache=True, max_cache_items=5):
        self.output_dir = output_dir
        self.audio_processor = AudioProcessor()
        self.api_utils = ApiUtils()
        self.whisper_service = WhisperService()
        self.whisper_api_service = None  # APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚ŒãŸã¨ãã«åˆæœŸåŒ–
        self.text_merger = EnhancedTextMerger(
            overlap_threshold=SEGMENT_MERGE_CONFIG['overlap_threshold'],
            min_overlap_words=SEGMENT_MERGE_CONFIG['min_overlap_words'],
            enable_context_analysis=SEGMENT_MERGE_CONFIG['enable_context_analysis']
        )

        # éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        self.enable_cache = enable_cache
        if enable_cache:
            self.cache_manager = AudioCacheManager(max_cache_items=max_cache_items)
            logger.info(f"éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½: æœ‰åŠ¹ (æœ€å¤§{max_cache_items}ä»¶)")
        else:
            self.cache_manager = None
            logger.info("éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½: ç„¡åŠ¹")
    
    def test_api_connection(self, api_key):
        """GeminiAPIã®æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        return self.api_utils.test_api_connection(api_key)

    def _check_response_safety(self, response, segment_num=None):
        """Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯

        Args:
            response: Gemini APIã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
            segment_num: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç•ªå·ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†æ™‚ã®ã¿ï¼‰

        Raises:
            TranscriptionError: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å•é¡ŒãŒã‚ã‚‹å ´åˆ
        """
        try:
            if not hasattr(response, 'candidates') or not response.candidates:
                return

            candidate = response.candidates[0]
            if not hasattr(candidate, 'finish_reason'):
                return

            finish_reason = candidate.finish_reason
            segment_info = f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_num}: " if segment_num else ""

            # finish_reasonã®ç¨®é¡:
            # 0 or FINISH_REASON_STOP: æ­£å¸¸çµ‚äº†
            # 1 or FINISH_REASON_MAX_TOKENS: ãƒˆãƒ¼ã‚¯ãƒ³æ•°ä¸Šé™
            # 2 or FINISH_REASON_SAFETY: å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚‹ãƒ–ãƒ­ãƒƒã‚¯
            # 3 or FINISH_REASON_RECITATION: å¼•ç”¨/è»¢è¼‰ã®æ¤œå‡º
            # 4: è‘—ä½œæ¨©ä¿è­·ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ¤œå‡º
            # 5 or FINISH_REASON_OTHER: ãã®ä»–ã®ç†ç”±

            if finish_reason == 2:
                error_msg = f"{segment_info}å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ - éŸ³å£°ã®å†…å®¹ãŒå®‰å…¨æ€§åŸºæº–ã«æŠµè§¦ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
                solution = (
                    "å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯ç·©å’Œè¨­å®šæ¸ˆã¿ã§ã™ãŒã€ãã‚Œã§ã‚‚ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚\n"
                    "ä»¥ä¸‹ã‚’ãŠè©¦ã—ãã ã•ã„ï¼š\n"
                    "1. Whisperã‚¨ãƒ³ã‚¸ãƒ³ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†ã§å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãªã—ï¼‰\n"
                    "2. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã—ã¦å•é¡Œã®ç®‡æ‰€ã‚’ç‰¹å®šã™ã‚‹\n"
                    "3. å•é¡Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã¿ã‚¹ã‚­ãƒƒãƒ—ã—ã¦å‡¦ç†ã‚’ç¶šè¡Œã™ã‚‹"
                )
                logger.error(f"{error_msg} - å¯¾å‡¦æ³•: {solution}")
                raise TranscriptionError(
                    error_msg,
                    error_code="SAFETY_FILTER",
                    user_message=f"{error_msg}\nğŸ’¡ å¯¾å‡¦æ³•: {solution}",
                    solution=solution
                )
            elif finish_reason == 3:
                error_msg = f"{segment_info}å¿œç­”ãŒæ—¢å­˜ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å¼•ç”¨ã¨ã—ã¦æ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚"
                logger.warning(error_msg)
                # å¼•ç”¨æ¤œå‡ºã¯è­¦å‘Šã®ã¿ã§ç¶šè¡Œ
            elif finish_reason == 4:
                error_msg = f"{segment_info}å¿œç­”ãŒè‘—ä½œæ¨©ä¿è­·ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã—ã¦æ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
                solution = "éŸ³å£°ã«å«ã¾ã‚Œã‚‹éŸ³æ¥½ã‚„BGMã‚’å‰Šé™¤ã™ã‚‹ã‹ã€åˆ¥ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
                logger.error(f"{error_msg} - å¯¾å‡¦æ³•: {solution}")
                raise TranscriptionError(
                    error_msg,
                    error_code="COPYRIGHT_CONTENT",
                    user_message=f"{error_msg}\nğŸ’¡ å¯¾å‡¦æ³•: {solution}",
                    solution=solution
                )
            elif finish_reason not in [0, 1]:
                error_msg = f"{segment_info}ç•°å¸¸ãªçµ‚äº†ç†ç”±ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ (finish_reason={finish_reason})"
                logger.warning(error_msg)

        except TranscriptionError:
            # TranscriptionErrorã¯ãã®ã¾ã¾å†é€å‡º
            raise
        except Exception as e:
            # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯ãƒ­ã‚°ã®ã¿
            logger.debug(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def get_output_files(self):
        """å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        files = []
        for file in os.listdir(self.output_dir):
            if file.endswith('.txt'):
                file_path = os.path.join(self.output_dir, file)
                mod_time = os.path.getmtime(file_path)
                mod_date = datetime.datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d %H:%M')
                size = os.path.getsize(file_path)
                size_str = f"{size / 1024:.1f} KB"
                files.append((file, mod_date, size_str, mod_time))
        
        # æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        files.sort(key=lambda x: x[3], reverse=True)
        return files
    
    def process_file(self, input_file, process_type, api_key, prompts, status_callback=None,
                    preferred_model=None, engine='gemini', whisper_model='base',
                    save_to_output_dir=True, save_to_source_dir=False,
                    progress_value_callback=None, gemini_api_key=None):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã€çµæœã‚’è¿”ã™"""
        start_time = datetime.datetime.now()

        def update_status(message):
            logger.info(message)
            if status_callback:
                status_callback(message)

        def update_progress(value):
            if progress_value_callback:
                progress_value_callback(value)

        try:
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰
            update_progress(2)
            audio_path, cached_segments, from_cache = self._prepare_audio_file(input_file, update_status)
            update_progress(10)

            # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œï¼ˆã‚¨ãƒ³ã‚¸ãƒ³ã«å¿œã˜ã¦åˆ†å²ï¼‰
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ãŸå ´åˆã¯ã€ãã‚Œã‚’ä½¿ç”¨
            if engine == 'whisper':
                transcription = self._perform_whisper_transcription(
                    audio_path, update_status, whisper_model, cached_segments,
                    progress_callback=update_progress
                )
            elif engine == 'whisper-api':
                transcription = self._perform_whisper_api_transcription(
                    audio_path, api_key, update_status, cached_segments,
                    progress_callback=update_progress
                )
            else:  # gemini
                transcription = self._perform_transcription(
                    audio_path, api_key, update_status, preferred_model, cached_segments,
                    progress_callback=update_progress
                )
            update_progress(85)

            # è¿½åŠ å‡¦ç†ï¼ˆå¿…è¦ãªå ´åˆï¼‰
            final_text = self._perform_additional_processing(
                transcription, process_type, prompts, api_key, update_status, preferred_model
            )
            update_progress(95)

            # è¦ç´„ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆï¼ˆGemini APIã‚­ãƒ¼ãŒã‚ã‚‹å ´åˆï¼‰
            summary_title = None
            if gemini_api_key:
                update_status("è¦ç´„ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆä¸­...")
                summary_title = self.generate_summary_title(final_text, gemini_api_key)
                if summary_title:
                    update_status(f"ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆå®Œäº†: {summary_title}")

            # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            output_path = self._save_result(
                input_file, final_text, process_type, prompts, start_time, update_status,
                save_to_output_dir=save_to_output_dir, save_to_source_dir=save_to_source_dir,
                summary_title=summary_title
            )
            update_progress(100)

            return output_path
            
        except Exception as e:
            logger.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
            update_status(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise FileProcessingError(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    def _prepare_audio_file(self, input_file, update_status):
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ï¼ˆå¤‰æ›ãƒ»åœ§ç¸®ãƒ»åˆ†å‰²ï¼‰

        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚Œã°å†åˆ©ç”¨ã€ãªã‘ã‚Œã°å‡¦ç†ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜

        Returns:
            (audio_path, segment_files, from_cache) ã®ã‚¿ãƒ—ãƒ«
        """
        # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—
        original_size_mb = get_file_size_mb(input_file)
        audio_duration_sec = self.audio_processor.get_audio_duration(input_file)
        duration_str = format_duration(audio_duration_sec) if audio_duration_sec else "ä¸æ˜"

        logger.info(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™é–‹å§‹: {os.path.basename(input_file)}, ã‚µã‚¤ã‚º={original_size_mb:.2f}MB, é•·ã•={duration_str}")
        update_status(f"å‡¦ç†é–‹å§‹: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º={original_size_mb:.2f}MB, é•·ã•={duration_str}")

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
        if self.enable_cache and self.cache_manager:
            cache_entry = self.cache_manager.get_cache_entry(input_file)
            if cache_entry:
                cache_id = cache_entry['cache_id']
                processed_audio, segments = self.cache_manager.get_cached_files(cache_id)

                if processed_audio:
                    update_status(f"âœ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿: {os.path.basename(input_file)}")
                    logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨: processed={processed_audio}, segments={len(segments) if segments else 0}")
                    return processed_audio, segments, True

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„å ´åˆã¯é€šå¸¸å‡¦ç†
        update_status("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›ä¸­...")
        audio_path = self.audio_processor.convert_audio(input_file)

        # é•·æ™‚é–“éŸ³å£°ã‚„å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã¯åˆ†å‰²ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
        file_size_mb = get_file_size_mb(audio_path)
        needs_split = (
            file_size_mb > MAX_AUDIO_SIZE_MB or
            (audio_duration_sec and audio_duration_sec > MAX_AUDIO_DURATION_SEC)
        )

        segment_files = None

        if needs_split:
            if file_size_mb > MAX_AUDIO_SIZE_MB:
                update_status(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚åœ§ç¸®ã‚’å®Ÿè¡Œã—ã¾ã™")
                audio_path = self.audio_processor.compress_audio(
                    audio_path, MAX_AUDIO_SIZE_MB, update_status
                )
                if not audio_path:
                    raise AudioProcessingError("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åœ§ç¸®ã«å¤±æ•—ã—ã¾ã—ãŸ")

            # åˆ†å‰²å‡¦ç†
            update_status("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ä¸­...")
            segment_files = self.audio_processor.split_audio(audio_path, callback=update_status)
            if segment_files:
                update_status(f"{len(segment_files)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã—ã¾ã—ãŸ")

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        if self.enable_cache and self.cache_manager:
            try:
                self.cache_manager.save_cache_entry(
                    input_file, audio_path, segment_files, audio_duration_sec
                )
                update_status("âœ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ãŸ")
            except Exception as e:
                logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")

        return audio_path, segment_files, False
    
    def _perform_transcription(self, audio_path, api_key, update_status, preferred_model=None, cached_segments=None, progress_callback=None):
        """æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’ä½¿ç”¨
        if cached_segments:
            logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨: {len(cached_segments)}å€‹")
            return self._perform_segmented_transcription(
                audio_path, api_key, update_status, preferred_model, cached_segments,
                progress_callback=progress_callback
            )

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨é•·ã•ã‚’å†ãƒã‚§ãƒƒã‚¯
        file_size_mb = get_file_size_mb(audio_path)
        audio_duration_sec = self.audio_processor.get_audio_duration(audio_path)

        needs_split = (
            file_size_mb > MAX_AUDIO_SIZE_MB or
            (audio_duration_sec and audio_duration_sec > MAX_AUDIO_DURATION_SEC)
        )

        if needs_split:
            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²å‡¦ç†ã‚’å®Ÿè¡Œ: ã‚µã‚¤ã‚º={file_size_mb:.2f}MB, é•·ã•={audio_duration_sec}s")
            return self._perform_segmented_transcription(
                audio_path, api_key, update_status, preferred_model,
                progress_callback=progress_callback
            )
        else:
            logger.info(f"å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’å®Ÿè¡Œ: ã‚µã‚¤ã‚º={file_size_mb:.2f}MB")
            if progress_callback:
                progress_callback(15)
            result = self._perform_single_transcription(audio_path, api_key, update_status, preferred_model)
            if progress_callback:
                progress_callback(80)
            return result
    
    def _perform_whisper_transcription(self, audio_path, update_status, whisper_model='base', cached_segments=None, progress_callback=None):
        """Whisperã‚’ä½¿ç”¨ã—ãŸæ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’ä½¿ç”¨
        if cached_segments:
            logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨: {len(cached_segments)}å€‹")
            return self._perform_whisper_segmented_transcription(
                audio_path, update_status, whisper_model, cached_segments,
                progress_callback=progress_callback
            )

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯
        file_size_mb = get_file_size_mb(audio_path)
        audio_duration_sec = self.audio_processor.get_audio_duration(audio_path)

        # Whisperã¯å¤§ãã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‡¦ç†ã§ãã‚‹ãŒã€é•·æ™‚é–“ã®éŸ³å£°ã¯åˆ†å‰²ã—ãŸæ–¹ãŒå®‰å®š
        needs_split = audio_duration_sec and audio_duration_sec > MAX_AUDIO_DURATION_SEC

        if needs_split:
            logger.info(f"Whisperåˆ†å‰²å‡¦ç†ã‚’å®Ÿè¡Œ: é•·ã•={audio_duration_sec}s")
            return self._perform_whisper_segmented_transcription(
                audio_path, update_status, whisper_model,
                progress_callback=progress_callback
            )
        else:
            logger.info(f"Whisperå˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’å®Ÿè¡Œ: ã‚µã‚¤ã‚º={file_size_mb:.2f}MB")
            if progress_callback:
                progress_callback(15)
            result = self._perform_whisper_single_transcription(audio_path, update_status, whisper_model)
            if progress_callback:
                progress_callback(80)
            return result
    
    def _perform_whisper_api_transcription(self, audio_path, api_key, update_status, cached_segments=None, progress_callback=None):
        """OpenAI Whisper APIã‚’ä½¿ç”¨ã—ãŸæ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ"""
        # Whisper APIã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
        if not self.whisper_api_service or self.whisper_api_service.api_key != api_key:
            self.whisper_api_service = WhisperApiService(api_key=api_key)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆWhisper APIã¯25MBä»¥ä¸‹ï¼‰
        file_size_mb = get_file_size_mb(audio_path)
        audio_duration_sec = self.audio_processor.get_audio_duration(audio_path)
        
        if file_size_mb > 25:
            raise AudioProcessingError(
                f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ï¼ˆ{file_size_mb:.2f}MBï¼‰ã€‚"
                "Whisper APIã¯25MBä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚"
                "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã™ã‚‹ã‹ã€ãƒ­ãƒ¼ã‚«ãƒ«ã®Whisperã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
            )
        
        logger.info(f"Whisper APIæ–‡å­—èµ·ã“ã—é–‹å§‹: ã‚µã‚¤ã‚º={file_size_mb:.2f}MB, é•·ã•={format_duration(audio_duration_sec)}")
        update_status(f"Whisper APIã§æ–‡å­—èµ·ã“ã—ä¸­...")
        if progress_callback:
            progress_callback(15)

        try:
            text, metadata = self.whisper_api_service.transcribe(audio_path, language='ja')
            
            # æ–™é‡‘æƒ…å ±ã‚’è¡¨ç¤º
            if audio_duration_sec:
                cost_info = self.whisper_api_service.estimate_cost(audio_duration_sec)
                update_status(
                    f"Whisper APIæ–‡å­—èµ·ã“ã—å®Œäº†\n"
                    f"- æ–™é‡‘: ${cost_info['cost_usd']:.4f} (ç´„{cost_info['cost_jpy']:.2f}å††)\n"
                    f"- éŸ³å£°é•·ã•: {format_duration(audio_duration_sec)}"
                )
            
            if progress_callback:
                progress_callback(80)
            return text

        except Exception as e:
            logger.error(f"Whisper APIæ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise TranscriptionError(f"Whisper APIæ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

    def _perform_single_transcription(self, audio_path, api_key, update_status, preferred_model=None):
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—"""
        genai.configure(api_key=api_key)
        model_name = self.api_utils.get_best_available_model(api_key, preferred_model)

        # éŸ³å£°ã®é•·ã•ã‚’å–å¾—ï¼ˆæ–™é‡‘è¨ˆç®—ç”¨ï¼‰
        audio_duration_sec = self.audio_processor.get_audio_duration(audio_path)

        # ãƒ¢ãƒ‡ãƒ«åã‚’ç›®ç«‹ã¤ã‚ˆã†ã«è¡¨ç¤º
        logger.info(f"âœ“ é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: {model_name}")
        update_status(f"âœ“ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
        update_status(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ä¸­...")

        model = genai.GenerativeModel(
            model_name,
            generation_config=AI_GENERATION_CONFIG,
            safety_settings=SAFETY_SETTINGS_TRANSCRIPTION  # æ–‡å­—èµ·ã“ã—ç”¨ã«å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ç·©å’Œ
        )

        with open(audio_path, 'rb') as audio_file:
            audio_data = audio_file.read()

        prompt = """ã“ã®éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ã‚’æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚ä»¥ä¸‹ã®ç‚¹ã‚’å®ˆã£ã¦æ­£ç¢ºã«æ›¸ãèµ·ã“ã—ã¦ãã ã•ã„ï¼š

1. è©±ã•ã‚ŒãŸå†…å®¹ã‚’ãã®ã¾ã¾æ–‡å­—ã«èµ·ã“ã™
2. è©±è€…ãŒè¤‡æ•°ã„ã‚‹å ´åˆã¯ã€è©±è€…ã®åŒºåˆ¥ã‚’è¡¨è¨˜ã™ã‚‹
3. è‡ªç„¶ãªæ–‡ç« ã®æµã‚Œã‚’ä¿ã¤
4. ä¸æ˜ç­ãªéƒ¨åˆ†ã¯[ä¸æ˜ç­]ã¨è¨˜è¼‰ã™ã‚‹
5. é•·ã„æ²ˆé»™ã¯[é–“]ã¨è¨˜è¼‰ã™ã‚‹

æ­£ç¢ºæ€§ã¨ä¸€è²«æ€§ã‚’æœ€å„ªå…ˆã«ã—ã¦ãã ã•ã„ã€‚"""

        parts = [
            {"inline_data": {"mime_type": AUDIO_MIME_TYPE, "data": audio_data}},
            {"text": prompt}
        ]

        response = model.generate_content(parts)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
        self._check_response_safety(response)

        if not response.text or response.text.strip() == "":
            raise TranscriptionError("æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã§ã—ãŸ")

        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã¨æ–™é‡‘ã‚’è¨ˆç®—ãƒ»è¡¨ç¤º
        process_usage_metadata(
            response, model_name,
            is_audio_input=True,
            audio_duration_seconds=audio_duration_sec,
            update_status=update_status
        )

        return response.text
    
    def _perform_segmented_transcription(self, audio_path, api_key, update_status, preferred_model=None, cached_segments=None, progress_callback=None):
        """åˆ†å‰²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ï¼ˆã‚¹ãƒãƒ¼ãƒˆçµ±åˆä»˜ãï¼‰"""
        genai.configure(api_key=api_key)
        model_name = self.api_utils.get_best_available_model(api_key, preferred_model)

        # ãƒ¢ãƒ‡ãƒ«åã‚’ç›®ç«‹ã¤ã‚ˆã†ã«è¡¨ç¤º
        logger.info(f"âœ“ é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: {model_name}")
        update_status(f"âœ“ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨
        if cached_segments:
            update_status(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨")
            segment_files = cached_segments
            update_status(f"{len(segment_files)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§å‡¦ç†ã—ã¾ã™")
        else:
            update_status(f"éŸ³å£°ã®é•·ã•ãŒé•·ã„ãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™")

            # éŸ³å£°ã‚’åˆ†å‰²
            segment_files = self.audio_processor.split_audio(audio_path, callback=update_status)
            if not segment_files:
                raise AudioProcessingError("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²ã«å¤±æ•—ã—ã¾ã—ãŸ")

            update_status(f"{len(segment_files)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã—ã¾ã—ãŸ")
        
        # ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä¸€åº¦ã ã‘ç”Ÿæˆï¼ˆå…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§å…±æœ‰ï¼‰
        model = genai.GenerativeModel(
            model_name,
            generation_config=AI_GENERATION_CONFIG,
            safety_settings=SAFETY_SETTINGS_TRANSCRIPTION
        )

        segment_transcriptions = []
        segment_info = []
        segment_costs = []
        segment_errors = []  # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¨˜éŒ²

        try:
            total = len(segment_files)
            for i, segment_file in enumerate(segment_files):
                update_status(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {i+1}/{total} ã‚’å‡¦ç†ä¸­")
                if progress_callback:
                    # 10%ã€œ80%ã®ç¯„å›²ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã«é€²æ—
                    pct = 10 + int((i / total) * 70)
                    progress_callback(pct)

                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ–‡å­—èµ·ã“ã—ï¼ˆæ”¹å–„ç‰ˆï¼‰
                result = self._transcribe_segment_enhanced(
                    segment_file, api_key, i+1, total, model_name, model=model
                )

                if isinstance(result, tuple):
                    segment_transcription, cost_info = result
                    if cost_info:
                        segment_costs.append(cost_info)
                else:
                    segment_transcription = result

                # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯: ã‚¨ãƒ©ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã¯çµæœã«å«ã‚ãªã„
                if isinstance(segment_transcription, str) and "å‡¦ç†ã‚¨ãƒ©ãƒ¼" in segment_transcription:
                    segment_errors.append({
                        'segment_index': i+1,
                        'error_text': segment_transcription
                    })
                    logger.warning(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {i+1} ã‚’ã‚¹ã‚­ãƒƒãƒ—: {segment_transcription}")
                else:
                    segment_transcriptions.append(segment_transcription)
                
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’è¨˜éŒ²ï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰
                segment_info.append({
                    'segment_index': i,
                    'total_segments': len(segment_files),
                    'file_path': segment_file
                })
        
        finally:
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self._cleanup_segments(segment_files, audio_path)
            
            # ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã‚’è¨˜éŒ²
            if segment_errors:
                error_summary = {
                    'summary': {
                        'total_segments': len(segment_files),
                        'failed_segments': len(segment_errors),
                        'success_segments': len(segment_files) - len(segment_errors),
                        'success_rate': f"{((len(segment_files) - len(segment_errors)) / len(segment_files) * 100):.1f}%"
                    },
                    'errors': segment_errors,
                    'recommendations': [
                        "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯æ–‡å­—èµ·ã“ã—çµæœã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
                        "ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã¯å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
                        "ã‚¨ãƒ©ãƒ¼ãŒç¶šãå ´åˆã¯ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚„å“è³ªã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                    ]
                }
                logger.warning(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼: {json.dumps(error_summary, ensure_ascii=False)}")

                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
                update_status(
                    f"\nâš ï¸ ä¸€éƒ¨ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n"
                    f"- æˆåŠŸ: {error_summary['summary']['success_segments']}/{error_summary['summary']['total_segments']}\n"
                    f"- å¤±æ•—: {error_summary['summary']['failed_segments']}/{error_summary['summary']['total_segments']}\n"
                    f"è©³ç´°ã¯ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                )

                # ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                try:
                    audio_dir = os.path.dirname(audio_path) if audio_path else OUTPUT_DIR
                    if audio_dir and os.path.exists(audio_dir):
                        error_summary_path = os.path.join(
                            audio_dir,
                            f"transcription_errors_{get_timestamp()}.json"
                        )
                        with open(error_summary_path, 'w', encoding='utf-8') as f:
                            json.dump(error_summary, f, ensure_ascii=False, indent=2)
                        logger.info(f"ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜: {error_summary_path}")
                    else:
                        logger.warning(f"ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã®ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {audio_dir}")
                except Exception as e:
                    logger.error(f"ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã®ä¿å­˜ã«å¤±æ•—: {str(e)}")
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã®ã‚³ã‚¹ãƒˆæƒ…å ±ã‚’é›†è¨ˆ
        if segment_costs:
            total_input_tokens = sum(cost["input_tokens"] for cost in segment_costs)
            total_output_tokens = sum(cost["output_tokens"] for cost in segment_costs)
            total_cost = sum(cost["total_cost"] for cost in segment_costs)
            
            combined_cost_info = {
                "input_tokens": total_input_tokens,
                "output_tokens": total_output_tokens,
                "total_cost": total_cost,
                "input_cost": sum(cost["input_cost"] for cost in segment_costs),
                "output_cost": sum(cost["output_cost"] for cost in segment_costs)
            }
            
            usage_text = format_token_usage(combined_cost_info)
            update_status(f"å…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡: {usage_text}")
        
        # ã‚¹ãƒãƒ¼ãƒˆçµ±åˆã‚’å®Ÿè¡Œ
        if SEGMENT_MERGE_CONFIG['enable_smart_merge']:
            update_status("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’çµ±åˆä¸­...")
            merged_text = self.text_merger.merge_segments_with_context(
                segment_transcriptions, segment_info
            )
            update_status("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµ±åˆå®Œäº†")
            return merged_text
        else:
            # å¾“æ¥ã®æ–¹æ³•ã§çµåˆ
            return "\n\n".join(segment_transcriptions)
    
    def _transcribe_segment_enhanced(self, segment_file, api_key, segment_num, total_segments, model_name, model=None):
        """æ”¹å–„ã•ã‚ŒãŸå˜ä¸€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ–‡å­—èµ·ã“ã—"""
        try:
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®éŸ³å£°ã®é•·ã•ã‚’å–å¾—ï¼ˆæ–™é‡‘è¨ˆç®—ç”¨ï¼‰
            segment_duration_sec = self.audio_processor.get_audio_duration(segment_file)

            # ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒæ¸¡ã•ã‚Œãªã„å ´åˆã®ã¿ç”Ÿæˆ
            if model is None:
                model = genai.GenerativeModel(
                    model_name,
                    generation_config=AI_GENERATION_CONFIG,
                    safety_settings=SAFETY_SETTINGS_TRANSCRIPTION
                )

            with open(segment_file, 'rb') as audio_file:
                audio_data = audio_file.read()

            # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚’è€ƒæ…®ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            if segment_num == 1:
                context_instruction = "ã“ã‚Œã¯éŸ³å£°ã®æœ€åˆã®éƒ¨åˆ†ã§ã™ã€‚"
            elif segment_num == total_segments:
                context_instruction = "ã“ã‚Œã¯éŸ³å£°ã®æœ€å¾Œã®éƒ¨åˆ†ã§ã™ã€‚å‰ã®éƒ¨åˆ†ã‹ã‚‰è‡ªç„¶ã«ç¶šãã‚ˆã†ã«æ–‡å­—èµ·ã“ã—ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"
            else:
                context_instruction = f"ã“ã‚Œã¯éŸ³å£°ã®ä¸­é–“éƒ¨åˆ†ï¼ˆ{segment_num}/{total_segments}ï¼‰ã§ã™ã€‚å‰å¾Œã®éƒ¨åˆ†ã¨è‡ªç„¶ã«ç¹‹ãŒã‚‹ã‚ˆã†ã«æ–‡å­—èµ·ã“ã—ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"

            prompt = f"""ã“ã®éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ã‚’æ—¥æœ¬èªã§è¡Œã£ã¦ãã ã•ã„ã€‚

{context_instruction}

ä»¥ä¸‹ã®ç‚¹ã‚’å®ˆã£ã¦æ­£ç¢ºã«æ›¸ãèµ·ã“ã—ã¦ãã ã•ã„ï¼š
1. è©±ã•ã‚ŒãŸå†…å®¹ã‚’ãã®ã¾ã¾æ–‡å­—ã«èµ·ã“ã™
2. è©±è€…ãŒè¤‡æ•°ã„ã‚‹å ´åˆã¯ã€è©±è€…ã®åŒºåˆ¥ã‚’è¡¨è¨˜ã™ã‚‹
3. è‡ªç„¶ãªæ–‡ç« ã®æµã‚Œã‚’ä¿ã¤
4. ä¸æ˜ç­ãªéƒ¨åˆ†ã¯[ä¸æ˜ç­]ã¨è¨˜è¼‰ã™ã‚‹
5. æ–‡ã®é€”ä¸­ã§åˆ‡ã‚Œã‚‹å ´åˆã¯ã€è‡ªç„¶ãªåŒºåˆ‡ã‚Šã§çµ‚ã‚ã‚‰ã›ã‚‹
6. é‡è¤‡ã‚„ç¹°ã‚Šè¿”ã—ãŒã‚ã‚‹å ´åˆã¯é©åˆ‡ã«å‡¦ç†ã™ã‚‹

æ­£ç¢ºæ€§ã¨ä¸€è²«æ€§ã‚’æœ€å„ªå…ˆã«ã—ã€å¾Œã§ä»–ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨çµ±åˆã•ã‚Œã‚‹ã“ã¨ã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚"""

            parts = [
                {"inline_data": {"mime_type": AUDIO_MIME_TYPE, "data": audio_data}},
                {"text": prompt}
            ]

            response = model.generate_content(parts)

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
            self._check_response_safety(response, segment_num=segment_num)

            if not response.text or response.text.strip() == "":
                raise TranscriptionError(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_num} ã®æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã§ã—ãŸ")

            # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†ã§ã¯è¡¨ç¤ºã¯æ§ãˆã‚ã«ï¼‰
            input_tokens, output_tokens = extract_usage_metadata(response)
            segment_cost_info = None
            if input_tokens is not None and output_tokens is not None:
                segment_cost_info = calculate_gemini_cost(
                    model_name, input_tokens, output_tokens,
                    is_audio_input=True, audio_duration_seconds=segment_duration_sec
                )

            return response.text.strip(), segment_cost_info
            
        except Exception as e:
            error_category, error_detail = self._classify_segment_error(e, segment_num, segment_file, total_segments, model_name)
            return f"[ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_num} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {error_category} - {error_detail}]", None

    def _classify_segment_error(self, exception, segment_num, segment_file, total_segments, model_name):
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼ã‚’åˆ†é¡ã—ã€ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹

        Returns:
            (error_category, error_detail) ã®ã‚¿ãƒ—ãƒ«
        """
        error_details = {
            'segment_num': segment_num,
            'total_segments': total_segments,
            'segment_file': segment_file,
            'error_type': type(exception).__name__,
            'error_message': str(exception),
            'model': model_name
        }

        error_str = str(exception).lower()

        if 'audio input modality is not enabled' in error_str or 'audio input is not supported' in error_str:
            error_category = "ãƒ¢ãƒ‡ãƒ«éå¯¾å¿œ"
            error_detail = "é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯éŸ³å£°å…¥åŠ›ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“"
            solution = "åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚Flashç³»ãƒ¢ãƒ‡ãƒ«ï¼ˆgemini-2.5-flashç­‰ï¼‰ã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
        elif 'rate limit' in error_str or '429' in error_str:
            error_category = "APIãƒ¬ãƒ¼ãƒˆåˆ¶é™"
            error_detail = "APIã®å‘¼ã³å‡ºã—å›æ•°ãŒä¸Šé™ã«é”ã—ã¾ã—ãŸ"
            solution = "æ•°åˆ†å¾…ã£ã¦ã‹ã‚‰å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚ã¾ãŸã¯ã€æœ‰æ–™ãƒ—ãƒ©ãƒ³ã¸ã®ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚’ã”æ¤œè¨ãã ã•ã„ã€‚"
        elif 'timeout' in error_str:
            error_category = "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ"
            error_detail = "APIå¿œç­”ã«æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã¾ã—ãŸ"
            solution = "éŸ³å£°ã®å†…å®¹ãŒè¤‡é›‘ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
        elif 'network' in error_str or 'connection' in error_str:
            error_category = "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶š"
            error_detail = "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã«å•é¡ŒãŒã‚ã‚Šã¾ã™"
            solution = "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ã‹ã‚‰å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
        elif 'authentication' in error_str or '401' in str(exception) or '403' in str(exception):
            error_category = "èªè¨¼å¤±æ•—"
            error_detail = "APIã‚­ãƒ¼ãŒç„¡åŠ¹ã¾ãŸã¯æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“"
            solution = "APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        elif 'finish_reason' in error_str and '4' in error_str:
            error_category = "è‘—ä½œæ¨©ä¿è­·ã‚³ãƒ³ãƒ†ãƒ³ãƒ„"
            error_detail = "éŸ³æ¥½ã‚„è‘—ä½œæ¨©ä¿è­·ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
            solution = "éŸ³å£°ã«å«ã¾ã‚Œã‚‹éŸ³æ¥½ã‚„BGMã‚’å‰Šé™¤ã™ã‚‹ã‹ã€åˆ¥ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
        elif 'copyrighted' in error_str or 'è‘—ä½œæ¨©' in str(exception):
            error_category = "è‘—ä½œæ¨©ä¿è­·ã‚³ãƒ³ãƒ†ãƒ³ãƒ„"
            error_detail = "éŸ³æ¥½ã‚„è‘—ä½œæ¨©ä¿è­·ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
            solution = "éŸ³å£°ã«å«ã¾ã‚Œã‚‹éŸ³æ¥½ã‚„BGMã‚’å‰Šé™¤ã™ã‚‹ã‹ã€åˆ¥ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
        elif 'safety' in error_str or 'å®‰å…¨æ€§' in str(exception) or 'blocked' in error_str:
            error_category = "å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"
            error_detail = "éŸ³å£°ã®å†…å®¹ãŒå®‰å…¨æ€§åŸºæº–ã«æŠµè§¦ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
            solution = "éŸ³å£°ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚éæ¿€ãªè¡¨ç¾ã‚„ä¸é©åˆ‡ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€å‡¦ç†ã§ãã¾ã›ã‚“ã€‚"
        elif '500' in str(exception) or 'internal' in error_str:
            error_category = "ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼"
            error_detail = f"{type(exception).__name__}"
            solution = "Googleå´ã®ã‚µãƒ¼ãƒãƒ¼ã§ä¸€æ™‚çš„ãªå•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚æ•°åˆ†å¾…ã£ã¦ã‹ã‚‰å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
        else:
            error_category = "äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼"
            error_detail = f"{type(exception).__name__}: {str(exception)}"
            solution = "ã‚¨ãƒ©ãƒ¼ãŒç¶šãå ´åˆã¯ã€åˆ¥ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è©¦ã™ã‹ã€ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

        # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        try:
            segment_dir = os.path.dirname(segment_file) if segment_file else tempfile.gettempdir()
            if segment_dir and os.path.exists(segment_dir):
                error_log_path = os.path.join(
                    segment_dir,
                    f"segment_{segment_num}_error.log"
                )
                error_details['error_category'] = error_category
                error_details['error_detail'] = error_detail
                error_details['solution'] = solution
                with open(error_log_path, 'w', encoding='utf-8') as f:
                    json.dump(error_details, f, ensure_ascii=False, indent=2)
        except Exception as log_error:
            logger.debug(f"ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ä¿å­˜ã«å¤±æ•—: {str(log_error)}")

        logger.error(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment_num} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {error_category} - {error_detail}")
        logger.debug(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {json.dumps(error_details, ensure_ascii=False)}")

        return error_category, error_detail
    
    def _perform_whisper_single_transcription(self, audio_path, update_status, whisper_model='base'):
        """Whisperã‚’ä½¿ç”¨ã—ãŸå˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—"""
        update_status(f"Whisperã§æ–‡å­—èµ·ã“ã—ä¸­... (ãƒ¢ãƒ‡ãƒ«: {whisper_model})")
        
        try:
            # Whisperã§æ–‡å­—èµ·ã“ã—
            text, metadata = self.whisper_service.transcribe(
                audio_path, 
                model_name=whisper_model,
                language='ja'
            )
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’è¡¨ç¤º
            duration = metadata.get('duration', 0)
            segments = metadata.get('segments', 0)
            device = metadata.get('device', 'CPU')
            
            update_status(
                f"Whisperæ–‡å­—èµ·ã“ã—å®Œäº†: "
                f"é•·ã•={format_duration(duration)}, "
                f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°={segments}, "
                f"ãƒ‡ãƒã‚¤ã‚¹={device}"
            )
            
            return text
            
        except Exception as e:
            logger.error(f"Whisperæ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise TranscriptionError(f"Whisperæ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    def _perform_whisper_segmented_transcription(self, audio_path, update_status, whisper_model='base', cached_segments=None, progress_callback=None):
        """Whisperã‚’ä½¿ç”¨ã—ãŸåˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨
        if cached_segments:
            update_status(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’Whisperã§å‡¦ç†ã—ã¾ã™ (ãƒ¢ãƒ‡ãƒ«: {whisper_model})")
            segment_files = cached_segments
            update_status(f"{len(segment_files)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§å‡¦ç†ã—ã¾ã™")
        else:
            update_status(f"éŸ³å£°ãŒé•·ã„ãŸã‚ã€åˆ†å‰²ã—ã¦Whisperã§å‡¦ç†ã—ã¾ã™ (ãƒ¢ãƒ‡ãƒ«: {whisper_model})")

            # éŸ³å£°ã‚’åˆ†å‰²
            segment_files = self.audio_processor.split_audio(audio_path, callback=update_status)
            if not segment_files:
                raise AudioProcessingError("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²ã«å¤±æ•—ã—ã¾ã—ãŸ")

            update_status(f"{len(segment_files)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã—ã¾ã—ãŸ")

        segment_transcriptions = []
        segment_info = []
        total = len(segment_files)

        try:
            for i, segment_file in enumerate(segment_files):
                update_status(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {i+1}/{total} ã‚’Whisperã§å‡¦ç†ä¸­")
                if progress_callback:
                    pct = 10 + int((i / total) * 70)
                    progress_callback(pct)
                
                # Whisperã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ–‡å­—èµ·ã“ã—
                text, metadata = self.whisper_service.transcribe_segment(
                    segment_file, 
                    segment_num=i+1,
                    total_segments=len(segment_files),
                    model_name=whisper_model,
                    language='ja'
                )
                
                segment_transcriptions.append(text)
                
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’è¨˜éŒ²
                segment_info.append({
                    'segment_index': i,
                    'total_segments': len(segment_files),
                    'file_path': segment_file,
                    'metadata': metadata
                })
        
        finally:
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self._cleanup_segments(segment_files, audio_path)
        
        # ã‚¹ãƒãƒ¼ãƒˆçµ±åˆã‚’å®Ÿè¡Œ
        if SEGMENT_MERGE_CONFIG['enable_smart_merge']:
            update_status("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’çµ±åˆä¸­...")
            merged_text = self.text_merger.merge_segments_with_context(
                segment_transcriptions, segment_info
            )
            update_status("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµ±åˆå®Œäº†")
            return merged_text
        else:
            # å¾“æ¥ã®æ–¹æ³•ã§çµåˆ
            return "\n\n".join(segment_transcriptions)
    
    def _cleanup_segments(self, segment_files, original_audio_path):
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        for segment_file in segment_files:
            if segment_file != original_audio_path and os.path.exists(segment_file):
                try:
                    os.unlink(segment_file)
                except OSError:
                    logger.warning(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—: {segment_file}")
    
    def _perform_additional_processing(self, transcription, process_type, prompts, api_key, update_status, preferred_model=None):
        """è¿½åŠ å‡¦ç†ï¼ˆè¦ç´„ã€è­°äº‹éŒ²ä½œæˆãªã©ï¼‰"""
        if process_type == "transcription":
            return transcription

        if process_type not in prompts:
            raise FileProcessingError(f"æŒ‡å®šã•ã‚ŒãŸå‡¦ç†ã‚¿ã‚¤ãƒ— '{process_type}' ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®šã«å­˜åœ¨ã—ã¾ã›ã‚“")

        # è¿½åŠ å‡¦ç†ã¯GeminiãŒå¿…è¦
        if not api_key:
            raise ApiConnectionError("è¿½åŠ å‡¦ç†ï¼ˆè¦ç´„ãƒ»è­°äº‹éŒ²ä½œæˆãªã©ï¼‰ã«ã¯Gemini APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")

        process_name = prompts[process_type]["name"]
        genai.configure(api_key=api_key)
        model_name = self.api_utils.get_best_available_model(api_key, preferred_model)

        # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º
        logger.info(f"âœ“ {process_name}ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
        update_status(f"âœ“ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
        update_status(f"{process_name}ã‚’ç”Ÿæˆä¸­...")
        
        prompt = prompts[process_type]["prompt"].replace("{transcription}", transcription)
        
        model = genai.GenerativeModel(
            model_name,
            generation_config=AI_GENERATION_CONFIG,
            safety_settings=SAFETY_SETTINGS_TRANSCRIPTION  # å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ç·©å’Œ
        )
        
        response = model.generate_content(prompt)
        if not response.text:
            raise TranscriptionError(f"{process_name}ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã¨æ–™é‡‘ã‚’è¨ˆç®—ãƒ»è¡¨ç¤ºï¼ˆãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ï¼‰
        def update_usage_status(message):
            update_status(f"{process_name}{message}")
        
        process_usage_metadata(
            response, model_name,
            is_audio_input=False,
            update_status=update_usage_status
        )
        
        return response.text
    
    def _get_unique_path(self, file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒé‡è¤‡ã™ã‚‹å ´åˆã€æœ«å°¾ã«é€£ç•ªã‚’ä»˜ä¸ã—ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ‘ã‚¹ã‚’è¿”ã™"""
        if not os.path.exists(file_path):
            return file_path

        base, ext = os.path.splitext(file_path)
        counter = 2
        while os.path.exists(f"{base}_{counter}{ext}"):
            counter += 1
        return f"{base}_{counter}{ext}"

    def generate_summary_title(self, text, api_key):
        """æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¦ç´„ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹

        Args:
            text: æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ
            api_key: Gemini APIã‚­ãƒ¼

        Returns:
            str or None: è¦ç´„ã‚¿ã‚¤ãƒˆãƒ«ã€‚å¤±æ•—æ™‚ã¯None
        """
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ããƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’ä½¿ç”¨ï¼ˆéŸ³å£°å‡¦ç†ä¸å‘ããƒ¢ãƒ‡ãƒ«ã‚’é™¤å¤–ï¼‰
            all_names = self.api_utils._get_available_models(api_key)
            available_names = [
                m for m in all_names
                if not any(kw in m.lower() for kw in ['-tts', 'live', 'thinking'])
            ]

            model_name = None
            for preferred in TITLE_GENERATION_MODELS:
                for available in available_names:
                    if preferred in available:
                        model_name = available
                        break
                if model_name:
                    break

            if not model_name:
                model_name = available_names[0] if available_names else None
            if not model_name:
                logger.warning("ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ: åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None

            logger.info(f"ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆãƒ¢ãƒ‡ãƒ«: {model_name}")

            # ãƒ†ã‚­ã‚¹ãƒˆã®å…ˆé ­2000æ–‡å­—ã‚’ä½¿ç”¨
            excerpt = text[:2000]

            prompt = (
                "ã“ã®æ–‡å­—èµ·ã“ã—ã®å†…å®¹ã‚’15ã€œ25æ–‡å­—ã§è¦ç´„ã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚\n"
                "ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ã†ã®ã§è¨˜å·ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚\n"
                "ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã‚„è£…é£¾ã¯ä¸è¦ã§ã™ã€‚\n\n"
                f"{excerpt}"
            )

            model = genai.GenerativeModel(
                model_name,
                generation_config={
                    'temperature': 0.1,
                    'max_output_tokens': 100,
                    'candidate_count': 1
                }
            )

            response = model.generate_content(prompt)

            if not response.text or not response.text.strip():
                logger.warning("ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ: ç©ºã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹")
                return None

            title = response.text.strip()
            # æœ€å¤§æ–‡å­—æ•°ã§åˆ‡ã‚Šè©°ã‚
            if len(title) > SUMMARY_TITLE_MAX_LENGTH:
                title = title[:SUMMARY_TITLE_MAX_LENGTH]

            # ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ãˆãªã„æ–‡å­—ã‚’é™¤å»
            title = sanitize_filename(title)
            if not title:
                logger.warning("ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ: ã‚µãƒ‹ã‚¿ã‚¤ã‚ºå¾Œã«ç©ºã«ãªã‚Šã¾ã—ãŸ")
                return None

            logger.info(f"ç”Ÿæˆã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«: {title}")
            return title

        except Exception as e:
            logger.warning(f"ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆã«å¤±æ•—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§å¾“æ¥ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½¿ç”¨ï¼‰: {str(e)}")
            return None

    def _save_result(self, input_file, final_text, process_type, prompts, start_time, update_status,
                     save_to_output_dir=True, save_to_source_dir=False, summary_title=None):
        """çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if not save_to_output_dir and not save_to_source_dir:
            logger.warning("ä¿å­˜å…ˆãŒæœªæŒ‡å®šã®ãŸã‚ã€outputãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã—ã¾ã™")
            save_to_output_dir = True

        timestamp = get_timestamp()
        base_name = os.path.splitext(os.path.basename(input_file))[0]

        # process_typeãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåã‚’ä½¿ç”¨
        if process_type in prompts:
            process_name = prompts[process_type]["name"]
        else:
            process_name = "æ–‡å­—èµ·ã“ã—"

        # ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆ
        if summary_title:
            # ã‚¿ã‚¤ãƒˆãƒ«ã‚ã‚Š: {è¦ç´„ã‚¿ã‚¤ãƒˆãƒ«}_æ–‡å­—èµ·ã“ã—_{å…ƒãƒ•ã‚¡ã‚¤ãƒ«å}.txt
            output_filename = f"{summary_title}_{process_name}_{base_name}.txt"
        else:
            # ã‚¿ã‚¤ãƒˆãƒ«ãªã—: {å…ƒãƒ•ã‚¡ã‚¤ãƒ«å}_æ–‡å­—èµ·ã“ã—_{ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—}.txtï¼ˆå¾“æ¥é€šã‚Šï¼‰
            output_filename = f"{base_name}_{process_name}_{timestamp}.txt"

        result_path = None

        # outputãƒ•ã‚©ãƒ«ãƒ€ã¸ä¿å­˜ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
        if save_to_output_dir:
            output_path = self._get_unique_path(os.path.join(self.output_dir, output_filename))
            output_filename = os.path.basename(output_path)  # é‡è¤‡å›é¿å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«åã«æ›´æ–°
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(final_text)
            result_path = output_path

        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚©ãƒ«ãƒ€ã¸ä¿å­˜ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
        if save_to_source_dir:
            source_dir = os.path.dirname(os.path.abspath(input_file))
            source_path = self._get_unique_path(os.path.join(source_dir, output_filename))
            if save_to_output_dir and result_path:
                shutil.copy2(result_path, source_path)
            else:
                with open(source_path, 'w', encoding='utf-8') as f:
                    f.write(final_text)
            if result_path is None:
                result_path = source_path
            update_status(f"å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚‚ä¿å­˜: {source_path}")

        # å‡¦ç†å®Œäº†ã®ãƒ­ã‚°
        end_time = datetime.datetime.now()
        process_time_str = format_process_time(start_time, end_time)
        output_size_kb = get_file_size_kb(result_path)
        update_status(
            f"å‡¦ç†å®Œäº†: {output_filename}\n"
            f"- å‡¦ç†æ™‚é–“: {process_time_str}\n"
            f"- å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {output_size_kb:.2f}KB"
        )

        return result_path
    
    def process_transcription_file(self, transcription_file, prompt_key, api_key, prompts, status_callback=None):
        """æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã®è¿½åŠ å‡¦ç†ã‚’å®Ÿè¡Œ"""
        start_time = datetime.datetime.now()
        
        def update_status(message):
            logger.info(message)
            if status_callback:
                status_callback(message)
        
        try:
            # æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            file_size_kb = get_file_size_kb(transcription_file)
            update_status(f"æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ{file_size_kb:.1f}KBï¼‰ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            
            with open(transcription_file, 'r', encoding='utf-8') as f:
                transcription = f.read()
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæƒ…å ±å–å¾—
            if prompt_key not in prompts:
                raise FileProcessingError(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ¼ '{prompt_key}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            prompt_info = prompts[prompt_key]
            process_name = prompt_info["name"]
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ™ãƒ¼ã‚¹éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆå…ƒã®æ–‡å­—èµ·ã“ã—å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
            base_name = os.path.basename(transcription_file)
            match = re.match(r'(.+?)_æ–‡å­—èµ·ã“ã—_\d+_\d+\.txt', base_name)
            if match:
                base_name = match.group(1)
            else:
                match = re.match(r'(.+?)_\d+_\d+\.txt', base_name)
                if match:
                    base_name = match.group(1)
            
            # APIã‚’ä½¿ç”¨ã—ã¦å‡¦ç†
            genai.configure(api_key=api_key)
            model_name = self.api_utils.get_best_available_model(api_key)

            # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º
            logger.info(f"âœ“ {process_name}ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
            update_status(f"âœ“ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
            update_status(f"{process_name}ã‚’ç”Ÿæˆä¸­...")
            
            model = genai.GenerativeModel(
                model_name,
                generation_config=AI_GENERATION_CONFIG
            )
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ–‡å­—èµ·ã“ã—çµæœã‚’åŸ‹ã‚è¾¼ã‚€
            prompt = prompt_info["prompt"].replace("{transcription}", transcription)
            
            response = model.generate_content(prompt)
            if not response.text:
                raise TranscriptionError(f"{process_name}ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
            timestamp = get_timestamp()
            output_filename = f"{base_name}_{process_name}_{timestamp}.txt"
            output_path = os.path.join(self.output_dir, output_filename)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            # å‡¦ç†å®Œäº†ã®ãƒ­ã‚°
            end_time = datetime.datetime.now()
            process_time_str = format_process_time(start_time, end_time)
            output_size_kb = get_file_size_kb(output_path)
            update_status(
                f"å‡¦ç†å®Œäº†: {os.path.basename(output_path)}\n"
                f"- å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_kb:.1f}KB\n"
                f"- å‡¦ç†æ™‚é–“: {process_time_str}\n"
                f"- ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}"
            )
            
            return output_path
            
        except Exception as e:
            update_status(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise FileProcessingError(f"æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
